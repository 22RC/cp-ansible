---
- include_role:
    name: confluent.common
  when: not common_role_completed|bool
  tags: common

- name: Gather OS Facts
  setup:
    # Only gathers items in list, filters out the rest
    filter: "{{item}}"
    gather_subset:
      - '!all'
  loop:
    - ansible_os_family
    - ansible_fqdn

# - name: "replace 'Hello' with 'Goodbye'"
#   debug:
#     msg: "{{ 'Hello World' | regex_replace('Hello', 'Goodbye') }}"

# - name: "replace 'Hello' with 'Goodbye'"
#   debug:
#     msg: "{{ test_variable }}"

# - name: "replace 'Hello' with 'Goodbye'"
#   debug:
#     msg: '{{ test_variable | regex_replace("\\", "\\\\") }}'

# - debug:
#     msg: "{{item}}"
#   loop: "{{ kafka_broker_final_properties | dict2items }}"

# - set_fact:
#     tmp_item:
#       name: "{{ item.key }}"
#       value: "{{ item.value | regex_replace("\\", "\\\\") }}"
#   register: tmp_items
#   loop: "{{ kafka_broker_final_properties | dict2items }}"

# - debug:
#     msg: "{{tmp_items}}"

# - set_fact:
#     res: "{{ tmp_items.results | map(attribute='ansible_facts.tmp_item') | list }}"
# - debug:
#     msg: "{{ res }}"

# - debug:
#     msg: '{{kafka_broker_final_properties | dict2items | map(attribute="value") | regex_replace("\\", "\\\\") }}'

# - debug:
#     msg: '{{kafka_broker_final_properties | regex_replace("\\", "\\\\") }}'

# - name: Add All Properties Containing 'password' to Encrypt List
#   debug:
#     msg: "{{ kafka_broker_final_properties | dict2items }}"

# - name: Add All Properties Containing 'password' to Encrypt List
#   debug:
#     msg: "{{ kafka_broker_final_properties | dict2items | map(attribute='key') | select('match', '.*password.*') }}"

# - name: Add All Properties Containing 'password' to Encrypt List
#   debug:
#     msg: "{{ kafka_broker_final_properties | dict2items | rejectattr('value', 'contains', 'password') | list}}"


- name: Stop Service and Remove Packages on Version Change
  include_role:
    name: confluent.common
    tasks_from: remove_packages.yml
  vars:
    service_name: "{{ kafka_broker_service_name }}"
  when: installation_method == "package"
  tags: package

- name: Install the Kafka Broker Packages
  yum:
    name: "{{ kafka_broker_packages | product([confluent_package_redhat_suffix]) | map('join') | list }}"
    state: latest
  when:
    - ansible_os_family == "RedHat"
    - installation_method == "package"
  ignore_errors: "{{ ansible_check_mode }}"
  tags: package
  notify: restart kafka

- name: Install the Kafka Broker Packages
  apt:
    name: "{{ kafka_broker_packages | product([confluent_package_debian_suffix]) | map('join') | list }}"
  when:
    - ansible_os_family == "Debian"
    - installation_method == "package"
  ignore_errors: "{{ ansible_check_mode }}"
  tags: package
  notify: restart kafka

- name: Kafka Broker group
  group:
    name: "{{kafka_broker_group}}"

- name: Check if Kafka Broker User Exists
  # Create user task must be skipped for non-linux users
  getent:
    database: passwd
    key: "{{kafka_broker_user}}"
  failed_when: false

- name: Create Kafka Broker user
  user:
    name: "{{kafka_broker_user}}"
    comment: Confluent Kafka
    system: true
    group: "{{kafka_broker_group}}"
  when: (getent_passwd|default({}))[kafka_broker_user] is not defined

# Archive File deployments need to create SystemD service units
# Copy the tarball's systemd service to the system
- name: Copy Kafka Broker Service from archive file to system
  copy:
    src: "{{binary_base_path}}/lib/systemd/system/{{kafka_broker.systemd_file|basename}}"
    remote_src: true
    dest: "{{kafka_broker.systemd_file}}"
    mode: 0644
    force: true
  when: installation_method == "archive"

- include_role:
    name: confluent.ssl
  vars:
    truststore_storepass: "{{kafka_broker_truststore_storepass}}"
    truststore_path: "{{kafka_broker_pkcs12_truststore_path}}"
    keystore_path: "{{kafka_broker_pkcs12_keystore_path}}"
    keystore_storepass: "{{kafka_broker_keystore_storepass}}"
    keystore_keypass: "{{kafka_broker_keystore_keypass}}"
    service_name: kafka_broker
    user: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
    hostnames: "{{ ([inventory_hostname, ansible_fqdn, ansible_host, ansible_ssh_host] + kafka_broker_listeners | get_hostnames(inventory_hostname)) | unique }}"
    ca_cert_path: "{{kafka_broker_ca_cert_path}}"
    cert_path: "{{kafka_broker_cert_path}}"
    key_path: "{{kafka_broker_key_path}}"
    export_certs: "{{kafka_broker_export_certs}}"
    create_bouncy_castle_keystore: "{{fips_enabled}}"
    bcfks_truststore_path: "{{kafka_broker_bcfks_truststore_path}}"
    bcfks_keystore_path: "{{kafka_broker_bcfks_keystore_path}}"
  when: >
    zookeeper_ssl_enabled|bool or
    kafka_broker_listeners | ssl_required(ssl_enabled) or
    kafka_broker_rest_ssl_enabled|bool or
    mds_broker_listener.ssl_enabled|bool or
    mds_tls_enabled|bool or
    schema_registry_ssl_enabled|bool
  tags: ssl

- include_tasks: rbac.yml
  when: rbac_enabled|bool

- name: Configure Kerberos
  include_role:
    name: confluent.kerberos
  vars:
    kerberos_group: "{{kafka_broker_group}}"
    kerberos_user: "{{kafka_broker_user}}"
    kerberos_keytab_path: "{{kafka_broker_kerberos_keytab_path}}"
    kerberos_keytab_destination_path: "{{kafka_broker_keytab_path}}"
    kerberos_handler: "restart kafka"
  when: "'GSSAPI' in kafka_broker_sasl_enabled_mechanisms or zookeeper_sasl_protocol == 'kerberos' or mds_broker_listener.sasl_protocol =='kerberos'"

- name: Copy Custom Kafka Files
  include_role:
    name: confluent.common
    tasks_from: copy_files.yml
  vars:
    copy_files: "{{kafka_broker_copy_files}}"
    user: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
  when: kafka_broker_copy_files | length > 0

- name: Set Permissions on /var/lib/kafka
  file:
    path: /var/lib/kafka/
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
    state: directory
    mode: 0750

# To avoid a catastrophic user error where root directory permissions get recursively changed
- name: Assert log.dirs Property not Misconfigured
  assert:
    that:
      - kafka_broker_final_properties['log.dirs'].split(',')[0] != "/"
    fail_msg: "Make sure datadir key is set to list of directories, NOT a string or dictionary."

- name: Set Permissions on Data Dirs
  file:
    path: "{{item}}"
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
    state: directory
    mode: 0750
  with_items: "{{ kafka_broker_final_properties['log.dirs'].split(',') }}"

- name: Set Permissions on Data Dir files
  file:
    path: "{{item}}"
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
    recurse: true
  with_items: "{{ kafka_broker_final_properties['log.dirs'].split(',') }}"

- name: Create Kafka Broker Config directory
  file:
    path: "{{ kafka_broker.config_file | dirname }}"
    state: directory
    mode: 0750
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"

# - set_fact: {"{{ key }}":"{{ val }}"}

# - set_fact: {"{{ item.key }}":"{{ item.val }}"}

# - name: Set fact
#   set_fact: 
#      "{{ variable_name }}": "{{ variable_value }}"

# - name: Backup Properties Dict
#   set_fact:
#     properties_backup: "{{ kafka_broker_final_properties }}"
#     # Secrets Protection CLI needs all backslashes escaped by a backslash. This filter turns \ into \\.
#     kafka_broker_final_properties: '{{ kafka_broker_final_properties | regex_replace("\\", "\\\\") }}'
#   when: kafka_broker_secrets_protection_enabled|bool

- name: Create Kafka Broker Config with Secrets Protection
  include_role:
    name: confluent.common
    tasks_from: secrets_protection.yml
  vars:
    final_properties: "{{ kafka_broker_final_properties }}"
    final_properties_dict_name: kafka_broker_final_properties
    encrypt_passwords: "{{ kafka_broker_secrets_protection_encrypt_passwords }}"
    properties: "{{ kafka_broker_secrets_protection_encrypt_properties }}"
    config_path: "{{ kafka_broker.config_file }}"
    config_template: server.properties.j2
    secrets_file: "{{ kafka_broker_secrets_protection_file }}"
    secrets_file_owner: "{{ kafka_broker_user }}"
    secrets_file_group: "{{ kafka_broker_group }}"
    handler: restart kafka
  when: kafka_broker_secrets_protection_enabled|bool

# - name: Restore Properties Dict
#   set_fact:
#     kafka_broker_final_properties: "{{properties_backup}}"
#   when: kafka_broker_secrets_protection_enabled|bool

- debug: var=kafka_broker_final_properties

- name: Create Kafka Broker Config
  template:
    src: server.properties.j2
    dest: "{{kafka_broker.config_file}}"
    mode: 0640
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
  notify: restart kafka
  when: not kafka_broker_secrets_protection_enabled|bool

- name: Create Kafka Broker Client Config
  template:
    src: client.properties.j2
    dest: "{{kafka_broker.client_config_file}}"
    mode: 0640
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"

# Zookeeper shell cannot read server.properties if secrets protection is enabled. Keeping a separate file.
- name: Create Zookeeper TLS Client Config
  template:
    src: zookeeper-tls-client.properties.j2
    dest: "{{kafka_broker.zookeeper_tls_client_config_file}}"
    mode: 0640
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
  when: zookeeper_ssl_enabled|bool

- name: Create Logs Directory
  file:
    path: "{{kafka_broker_log_dir}}"
    state: directory
    group: "{{kafka_broker_group}}"
    owner: "{{kafka_broker_user}}"
    mode: 0770

- name: Update Kafka log4j Config for Log Cleanup
  include_role:
    name: confluent.common
    tasks_from: update_log4j.yml
  vars:
    log4j_file: "{{kafka_broker.log4j_file}}"
    log4j_max_backup_index: "{{kafka_broker_max_log_files}}"
    log4j_max_file_size: "{{kafka_broker_log_file_size}}"
    log4j_root_logger: "{{kafka_broker_log4j_root_logger}}"
    handler: "restart kafka"
  when: kafka_broker_custom_log4j|bool

- name: Set Permissions on Log4j Conf
  file:
    path: "{{kafka_broker.log4j_file}}"
    group: "{{kafka_broker_group}}"
    owner: "{{kafka_broker_user}}"
    mode: 0640

- name: Create Kafka Broker Jolokia Config
  template:
    src: kafka_jolokia.properties.j2
    dest: "{{kafka_broker_jolokia_config}}"
    mode: 0640
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
  when: kafka_broker_jolokia_enabled|bool
  notify: restart kafka

- name: Create Kafka Broker Jaas Config
  template:
    src: kafka_server_jaas.conf.j2
    dest: "{{kafka_broker.jaas_file}}"
    mode: 0640
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
  when: "'GSSAPI' in kafka_broker_sasl_enabled_mechanisms or zookeeper_sasl_protocol in ['kerberos', 'digest']"
  notify: restart kafka

- name: Create SCRAM Users
  shell: |
    {% if kafka_broker_final_properties['zookeeper.set.acl']|default('false')|lower == 'true' %}KAFKA_OPTS='-Djava.security.auth.login.config={{kafka_broker.jaas_file}}'{% endif %} \
    {{ binary_base_path }}/bin/kafka-configs {% if zookeeper_ssl_enabled|bool %}--zk-tls-config-file {{ kafka_broker.zookeeper_tls_client_config_file if kafka_broker_secrets_protection_enabled else kafka_broker.config_file }}{% endif %} \
      --zookeeper {{ groups['zookeeper'][0] }}:{{zookeeper_client_port}} --alter \
      --add-config 'SCRAM-SHA-512=[password={{ item.value['password'] }}]' \
      --entity-type users --entity-name {{ item.value['principal'] }}
  loop: "{{ sasl_scram_users_final|dict2items }}"
  run_once: true
  when: "'SCRAM-SHA-512' in kafka_broker_sasl_enabled_mechanisms"
  no_log: "{{mask_secrets|bool}}"

- name: Create SCRAM 256 Users
  shell: |
    {% if kafka_broker_final_properties['zookeeper.set.acl']|default('false')|lower == 'true' %}KAFKA_OPTS='-Djava.security.auth.login.config={{kafka_broker.jaas_file}}'{% endif %} \
    {{ binary_base_path }}/bin/kafka-configs {% if zookeeper_ssl_enabled|bool %}--zk-tls-config-file {{ kafka_broker.zookeeper_tls_client_config_file if kafka_broker_secrets_protection_enabled else kafka_broker.config_file }}{% endif %} \
      --zookeeper {{ groups['zookeeper'][0] }}:{{zookeeper_client_port}} --alter \
      --add-config 'SCRAM-SHA-256=[password={{ item.value['password'] }}]' \
      --entity-type users --entity-name {{ item.value['principal'] }}
  loop: "{{ sasl_scram256_users_final|dict2items }}"
  run_once: true
  when: "'SCRAM-SHA-256' in kafka_broker_sasl_enabled_mechanisms"
  no_log: "{{mask_secrets|bool}}"

- name: Deploy JMX Exporter Config File
  copy:
    src: "{{kafka_broker_jmxexporter_config_source_path}}"
    dest: "{{kafka_broker_jmxexporter_config_path}}"
    mode: 0640
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
  when: kafka_broker_jmxexporter_enabled|bool

- name: Create Service Override Directory
  file:
    path: "{{kafka_broker.systemd_override | dirname }}"
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
    state: directory
    mode: 0640

- name: Write Service Overrides
  template:
    src: override.conf.j2
    dest: "{{ kafka_broker.systemd_override }}"
    mode: 0640
    owner: "{{kafka_broker_user}}"
    group: "{{kafka_broker_group}}"
  notify: restart kafka

- name: Tune virtual memory settings
  sysctl:
    name: "{{ item.key }}"
    value: "{{ item.value }}"
    state: present
    sysctl_file: "{{ kafka_broker_sysctl_file }}"
    reload: true
  with_dict: "{{ kafka_broker_sysctl }}"
  tags: sysctl

- name: Certs were Updated - Trigger Restart
  command: /bin/true
  notify: restart kafka
  when: certs_updated|bool

- meta: flush_handlers

- name: Kafka Started
  systemd:
    name: "{{kafka_broker_service_name}}"
    enabled: true
    state: started
  tags:
    - systemd

- name: Wait for Health Checks to Complete
  include_tasks: health_check.yml
  when:
    - kafka_broker_health_checks_enabled|bool
    - not ansible_check_mode

- name: Register Cluster
  include_tasks: register_cluster.yml
  when: kafka_broker_cluster_name|length > 0

- name: Create RBAC Rolebindings
  include_tasks: rbac_rolebindings.yml
  when: kafka_broker_additional_system_admins|length > 0
